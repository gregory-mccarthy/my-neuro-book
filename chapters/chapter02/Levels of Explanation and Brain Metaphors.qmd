# Levels of Explanation and Brain Metaphors

## Introduction  

This is a course about the **brain**. We will consider the constituent cells that comprise it and the anatomical structures and connections they form. But the course is equally about brain function. With an organ such as the **heart**, its role as a pump is easy to grasp. By analogy, one might assume the brain’s role is simply to **control behavior**. Yet the relationship between brain and behavior is far from straightforward. When we say the brain *controls* behavior, what do we really mean by control? And what do we mean by **behavior**? Is it limited to observable motor output, or does it also encompass internal **mentalistic processes** that are presumed to mediate between sensation and action?  

::: {.callout-note collapse="true"}  
### Author’s Bias: A Note on Theoretical Orientation  

My approach to human neuroscience reflects a particular philosophical stance that I want students to understand from the outset. I am a methodological **reductionist**: I believe that theories of behavior and cognition must ultimately be compatible with what we know about neural mechanisms, evolutionary pressures, and biological constraints.  

This does not mean that psychological phenomena can be neatly reduced to patterns of neural firing. Just as chemistry long provided valid theories before physics explained it mechanistically, psychological theories may anticipate insights from future neuroscience. But chemistry never violated the laws of physics, and psychology cannot disregard biological plausibility.  

At the same time, I recognize that complex systems exhibit **emergent properties** that cannot be predicted from their components alone. Neural networks—like weather systems or ecosystems—show behaviors that arise from interactions of simpler elements under specific conditions, often requiring statistical rather than deterministic descriptions.  

Throughout this book, you will notice this bias toward circuit-level explanations, evolutionary context, and skepticism toward theories that lack biological grounding. This orientation reflects one scientific path forward, though other thoughtful researchers emphasize different approaches.  
:::  

---

## Levels of Analysis: The Problem of Category Errors

One of the central challenges in linking brain structure to function is the risk of confusing **levels of analysis**. Concepts that are useful at the behavioral level are often reified as if they were literal brain mechanisms. This is especially problematic with **constructs** such as attention, working memory, or executive function—terms inferred from behavior rather than observed directly.  

Different approaches have been taken to explore the brain–behavior relationship. **Cognitive psychology** developed constructs to describe regularities in performance. **Cognitive neuroscience**, especially with the advent of neuroimaging, often asks where such constructs might be instantiated in the brain. And **cognitive neuropsychology**, working with patients who have focal brain lesions, used methods such as **double dissociation** to infer functional architecture. Each approach yielded insights, but each also risked blurring the line between behavioral description and neural mechanism.  

This is the danger of a **category error**. It is like mistaking the **map** for the **territory**. A map is a powerful tool for navigation, but it is not the landscape itself. Similarly, behavioral constructs organize and predict performance, but they are not the mechanisms that generate it. The fact that “maps” are useful at the behavioral level does not mean the brain must literally implement them as cartographic layouts. Place cells and grid cells, for example, support navigation through population codes that look nothing like a two-dimensional atlas. The lesson is that behavioral categories are not blueprints of neural architecture.  

To be clear, cognitive psychology itself did not begin by making this mistake. When Alan Baddeley proposed his model of working memory in the 1970s, he was explicit that it was a **behavioral theory**. The phonological loop, visuospatial sketchpad, and central executive were abstractions designed to explain regularities such as rehearsal span or selective interference. At that level, the model was enormously successful.  

The problem arose when cognitive neuroscience, armed with imaging tools, went searching for the phonological loop in parietal cortex or the central executive in prefrontal cortex. Colorful brain maps seemed to localize psychological constructs, but the underlying assumption was flawed: that a useful behavioral model must have a one-to-one counterpart in the brain.  

Even the more disciplined field of cognitive neuropsychology began with behavioral constructs. At Queen Square and elsewhere, researchers such as Elizabeth Warrington and Tim Shallice pioneered double dissociation: if lesion A impairs function X but spares Y, while lesion B impairs Y but spares X, then X and Y must rely on at least partially distinct neural mechanisms. This approach produced an impressive catalogue of dissociations—between recognizing objects versus faces, processing color versus motion, and understanding nouns versus verbs. But the categories being tested were psychological ones. Dissociations were real, but interpreting them as evidence for “modules” assumed that the brain’s divisions mirror the distinctions drawn at the behavioral level.  

::: {.callout-note collapse="true"}  
### Deeper Dive: Understanding Double Dissociations

A dissociation occurs when brain damage impairs one ability while sparing another. Such cases are striking, but a single dissociation may only show that one task is harder or more fragile than another. Double dissociations strengthen the inference by showing complementary patterns across patients: lesion A impairs X but spares Y, while lesion B impairs Y but spares X.  

A classic example comes from memory research. Patients with Korsakoff’s syndrome suffer profound long-term memory deficits yet often show normal digit span. By contrast, the patient KF, studied by Warrington and Shallice, could form new long-term memories but had a drastically reduced digit span. Taken together, these patterns suggested distinct short-term and long-term memory systems.  

This interpretation proved influential, but modern neuroscience offers a different view. Short-term memory often reflects sustained activity in perceptual circuits, while long-term memory involves synaptic changes in those same circuits. KF’s impairment may have reflected damage to left-hemisphere language pathways rather than a dedicated “short-term store.” The dissociations were real, but the categories they seemed to validate were behavioral constructs, not necessarily the brain’s own divisions.  
:::  

---

## Historical Metaphors: From Pneumatics to Computers

If levels of analysis shape the categories we use, **metaphors** shape the stories we tell. Throughout history, neuroscientists have drawn on the technologies of their era to explain the brain. Each metaphor was illuminating in its time, but each eventually constrained thought when mistaken for literal truth.  

In antiquity, the dominant technologies were hydraulics and pneumatics. Greeks and Romans, masters of aqueducts and pumps, imagined that vital spirits or pneuma flowed through hollow nerves like water through pipes. Galen’s physiology described the brain as a reservoir that distributed these animal spirits to the body. Muscles, in his account, contracted when infused with pneuma, much as bladders expand when filled. Within the framework of hydraulic engineering, this was a powerful and reasonable model.  

In the seventeenth century, René Descartes extended this pneumatic metaphor with the mechanical imagination of his age. At the gardens of Versailles he observed hydraulic automata: statues that struck, danced, or sprayed water when hidden valves opened. He imagined nerves as pipes carrying “animal spirits” and the pineal gland as the valve controlled by the soul. Muscles contracted, in his view, just as statues moved when water pressure filled their chambers.  

The age of clockwork soon brought a new metaphor. Elaborate automata, powered by springs and gears, captivated audiences. Birds that sang, dolls that played instruments, machines that walked—all demonstrated that intricate motion could arise from mechanism alone. The nervous system seemed, by analogy, to be clockwork: precise, deterministic, composed of interlocking parts.  

By the nineteenth century, the rise of electricity and telegraphy offered another model. Nerves came to be seen as wires conducting signals, the brain as a switchboard routing messages from one place to another. This metaphor was reinforced by discoveries of nerve conduction and action potentials, which did in fact involve electrical impulses, and by the telephone switchboard, which suggested cortical “centers” connected by fibers, with operators routing signals between them.  

In the twentieth century, as digital computers transformed science and society, the nervous system was recast once again. The computer metaphor became dominant: neurons as logic gates, circuits as information-processing units, thought as computation. With the von Neumann machine as template, the brain was reimagined as processor, memory, and bus. The vocabulary of computation—encode, retrieve, buffer, bandwidth—saturated neuroscience. Working memory was likened to RAM, attention to bandwidth, consolidation to storage transfer. The metaphor was enormously productive. But like those before it, it risked being mistaken for mechanism rather than scaffold.  

---

## Why Brains Are Not von Neumann Machines

The problem is not that brains differ from computers in detail, but that they differ in principle. Von Neumann machines separate memory from processing, rely on a central processor, and move data along buses. Brains do none of these things.  

In the brain, the same synapses that “store” information also transform it. Memory and processing are inseparable. Each neuron is simultaneously a memory element and a processor, integrating thousands of inputs and influencing thousands of outputs. There is no global bus shuttling data around, and no central executive fetching instructions. The brain’s 86 billion neurons compute in parallel, without a master controller.  

To recall your grandmother’s face is not to fetch a stored file but to reconstruct a new pattern of activity, shaped by current inputs and prior connectivity. The architecture does not implement an algorithm; it *is* the computation.  

The most efficient system for solving the equations of fluid flow in a stream is not a computer running those equations but the stream itself. Water flows by virtue of its physical properties; it does not calculate. Likewise, neural circuits may not implement algorithms in the computational sense but exhibit dynamics that yield adaptive behavior. As James Gibson argued, perception and action are rooted in resonance with environmental structure, not in symbol manipulation.  

Seen in this light, the computer metaphor belongs on the same continuum as pneuma, clockwork, and telegraphs. Each was useful, seductive, and misleading when taken literally.  

::: {.callout-note collapse="true"}  
### Deeper Dive: Computer Architectures

Von Neumann machines are general-purpose and can simulate other systems—parallel processors, analog circuits, even neural networks. But simulation is not the same as implementation. A laptop crunching equations of fluid dynamics is not the same as a river flowing downhill.  

Engineers are now building chips that abandon von Neumann’s strict separation of memory and processing. Neuromorphic chips (e.g., Intel’s *Loihi*, IBM’s *TrueNorth*) use circuits that mimic networks of spiking neurons, operating asynchronously and in parallel. Memristive devices collapse storage and computation into the same substrate, like synapses that both transmit and store. Analog computers, once set aside, are re-emerging for problems where continuous dynamics matter.  

These architectures remind us that von Neumann is not destiny. There are many ways to build a computer—and the brain may be better understood through models where memory and computation are inseparable, and dynamics arise from the physics of the system itself.  
:::  

---

## Reductionism and Complexity

::: {.callout-note collapse="true"}  
### Reductionism and Complexity

Reductionism holds that higher-level phenomena must remain consistent with lower-level processes. Physics constrains chemistry, chemistry constrains biology, biology constrains behavior. This is not simplistic determinism but a commitment to naturalism: psychology cannot float free of biology.  

Yet complexity arises when many elements interact. Even simple rules can generate nonlinear, chaotic, and unpredictable dynamics—as seen in flocking birds, weather systems, and brains. In such cases we often need probabilistic or dynamical models, not deterministic equations.  

Complexity does not invalidate reductionism; it shows why higher-level models are indispensable. The science of mind and behavior must therefore embrace both: reductionism to ensure biological grounding, and statistical/dynamical approaches to capture the richness that emerges when simple processes interact.  

**Glossary (local to box)**  
- **Reductionism** — Higher-level theories must align with lower-level principles.  
- **Emergence** — Novel properties arise from interactions of simpler elements.  
- **Complexity** — Collective behavior not predictable from parts alone.  
- **Chaos** — Small initial differences yield large, unpredictable outcomes.  
- **Dynamical systems** — Frameworks for describing how systems evolve over time.  
- **Statistical description** — Using averages, distributions, and probabilities to capture system behavior.  
:::  

---

## General Glossary

- **Attention** — A behavioral construct describing selective prioritization of information.  
- **Behavior** — Observable actions of an organism; sometimes extended to include internal mediating processes.  
- **Category error** — Mistaking a description at one level of analysis for a mechanism at another.  
- **Cognition** — Processes such as memory, reasoning, and problem solving, often described at the psychological level.  
- **Double dissociation** — A neuropsychological method where complementary patterns of impairment suggest independence of functions.  
- **Emergence** — The appearance of novel properties when many simple components interact.  
- **Memory (short-term / long-term)** — Behavioral categories for temporary versus enduring information retention.  
- **Metaphor (in neuroscience)** — Borrowed imagery from technology used to explain brain function (hydraulic, clockwork, computer).  
- **Reductionism** — The view that higher-level theories must remain consistent with lower-level biological and physical principles.  
- **Von Neumann architecture** — A computer design separating memory, processing, and control, with data transferred along buses.  

---

## Suggested Readings

- Baddeley, A. D. (2012). *Working Memory: Theories, Models, and Controversies*. Annual Review of Psychology, 63, 1–29.  
- Shallice, T. (1988). *From Neuropsychology to Mental Structure*. Cambridge University Press.  
- Bechtel, W. (2008). *Mental Mechanisms: Philosophical Perspectives on Cognitive Neuroscience*. Routledge.  
- Dupuy, J.-P. (2009). *On the Origins of Cognitive Science: The Mechanization of the Mind*. MIT Press.  
- Gibson, J. J. (1979). *The Ecological Approach to Visual Perception*. Houghton Mifflin.  